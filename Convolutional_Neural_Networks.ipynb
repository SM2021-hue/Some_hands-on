{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNNs for Face Identification \n",
    "\n",
    "We will perform face identification using a subset of the [Labeled Faces in the Wild (LFW) dataset](http://vis-www.cs.umass.edu/lfw/). Face identification is a multi-class calssification problem where we have training/testing images for a set of subjects (classes). In 2014, researchers were able to surpass human accuracy in facial identification tasks using CNN models (along with advanced deep learning techniques)! \n",
    "\n",
    "We will observe the performance of a traditional face identification method, [Eigenfaces](https://en.wikipedia.org/wiki/Eigenface). We will then build a CNN model in order to surpass the accuracy of the traditional Eigenfaces technique. In the process, we will learn about the great power of CNNs!\n",
    "\n",
    "### Requirements\n",
    "\n",
    "1. Python 3.6\n",
    "2. `pip install numpy`\n",
    "3. `pip install sklearn`\n",
    "4. `pip install matplotlib`\n",
    "5. `pip install tensorflow==2.0.0`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import fetch_lfw_people\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Activation, Conv2D, MaxPool2D,concatenate, AveragePooling2D, Flatten, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import SGD, RMSprop, Adam, Adagrad\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by downloading and setting up a subset of the aligned and segmented version of the LFW dataset. We will only get subjects with at least 20 corresponding images. We will also get the grayscale versions of the images. This may take a few minutes . . ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_x, data_y = fetch_lfw_people(min_faces_per_person=20, color=False, return_X_y=True)\n",
    "# normalize pixel values to [0,1]\n",
    "data_x = data_x / 255."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The downloaded `data_x` will be the flattened vector representation of the images. \n",
    "\n",
    "We will reshape the vector respresentations back into the original grayscale images and store the images back in `data_x`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_subjects = np.unique(data_y).shape[0]\n",
    "print(\"Number of subjects: {}\".format(np.unique(data_y).shape[0]))\n",
    "print(\"Number of images: {}\\n\".format(data_y.shape[0]))\n",
    "\n",
    "# image_x will contain the original grayscale images \n",
    "data_x = np.copy(data_x.reshape((data_x.shape[0], 62, 47, 1)))\n",
    "\n",
    "print(\"data_x shape: {}\".format(data_x.shape))\n",
    "print(\"data_y shape: {}\".format(data_y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the dataset is made up of `3023` images of `62` subjects (or classes). \n",
    "\n",
    "Each image is a `62x47x1`-dimensional matrix containing 8-bit (0-255) grayscale pixel values.\n",
    "\n",
    "Let's visualize a few of the grayscale images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "for i in range(5):\n",
    "    rnd_idx = np.random.choice(data_y.shape[0])\n",
    "    rnd_img = data_x[rnd_idx]\n",
    "    plt.figure()\n",
    "    plt.imshow(rnd_img[:, :, 0], cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's split the dataset into train and test sets so we can perform face identification!\n",
    "\n",
    "We will perform a `90/10` stratified split. This means that `90%` of each subject's images are placed in the train set, while the remaining `10%` of each subject's images are placed into the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, test_x, train_y, test_y = train_test_split(data_x, data_y, test_size=0.1, random_state=42)\n",
    "\n",
    "print(\"train_x shape: {}\".format(train_x.shape))\n",
    "print(\"train_y shape: {}\\n\".format(train_y.shape))\n",
    "\n",
    "print(\"test_x shape: {}\".format(test_x.shape))\n",
    "print(\"test_y shape: {}\".format(test_y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eigenfaces Overview\n",
    "\n",
    "Eigenfaces is a face identification technique proposed in 1987. It was a very popular algorithm through the 1990's and is still used today as a baseline algorithm when gauging the performance of proposed face identification techniques. Eigenfaces is used to extract features from facial images. Such facial features are more useful in identification tasks than the corresponding oringinal images. The facial features can then be used for identification by being classified by a multi-class classifier, such a logistic regression model. \n",
    "\n",
    "### Eigenfaces Details\n",
    "\n",
    "Eigenfaces is a Principcal Componet Analysis (PCA)-based dimensionality-reduction technique. Eigenfaces deals with the flattened vector representations of the face images. \n",
    "\n",
    "We give the vector representation of the training images as input to the algorithm. The output of the algoirthm is a set of Eigenfaces (vectors) which we can use to project vector representations of images into a lower-dimensional space which (hopefully) encode important facial features. \n",
    "\n",
    "Since the lower-dimensional space captures important facial features, Eigenfaces is used as a feature extraction technique. Given a facial image, we can reshape the image into a vector. Using the Eigenfaces, we reduce the dimensionality of the original vector into a vector which is more useful in identifying its corresponging subject. Therefore, we will use the Eigenfaces to extract facial features. Then, we will use a simple logistic regression classifier to classify the resulting facial features.\n",
    "\n",
    "Let's start by flattening the training facial images. Then we will continue by computing the Eigenfaces which capture `95%` of the variance of the original dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten images \n",
    "train_vector_x = train_x.reshape((train_x.shape[0], train_x.shape[1]*train_x.shape[2])) \n",
    "test_vector_x = test_x.reshape((test_x.shape[0], test_x.shape[1]*test_x.shape[2])) \n",
    "\n",
    "# retrieve eigenfaces\n",
    "pca = PCA(n_components=0.95, random_state=42)\n",
    "pca.fit(train_vector_x)\n",
    "eigenfaces = pca.components_\n",
    "\n",
    "print(\"Training vectors shape: {}\".format(train_vector_x.shape))\n",
    "print(\"Eigenfaces shape: {}\".format(eigenfaces.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see, if we flatten the training images to gather their vector representations, we recieve `2720` vectors of size `2914`. We also see that we have found `173` Eigenfaces vectors of size `2914`.\n",
    "\n",
    "If we reshape the set of Eigenfaces to the shape of the original images, they reveal intesting ghost faces (i.e. \"Eigenfaces\").\n",
    "\n",
    "Let's view the first `10` Eigenfaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    eigenface = eigenfaces[i].reshape((train_x.shape[1], train_x.shape[2]))\n",
    "    plt.figure()\n",
    "    plt.imshow(eigenface, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spooky!\n",
    "\n",
    "Now, let's use the Eigenfaces to extract facial features from the training and test set vectors. Since we have `173` Eigenfaces, we will reduce the dimensionality of the `2914`-dimensional train/test vectors to `173`-dimensional train/test feature vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features_x = np.dot(train_vector_x, eigenfaces.T)\n",
    "test_features_x = np.dot(test_vector_x, eigenfaces.T)\n",
    "\n",
    "print(\"Training vectors shape: {}\".format(train_vector_x.shape))\n",
    "print(\"Training features shape: {}\".format(train_features_x.shape))\n",
    "print(\"Testing vectors shape: {}\".format(test_vector_x.shape))\n",
    "print(\"Testing features shape: {}\".format(test_features_x.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Now that we have extracted facial features from the train and testing set, let's perform facial identification using a simple logistic regression model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# specify the input size of the feature vectors\n",
    "features = Input((train_features_x.shape[1],))\n",
    "# a single fully-connected layer to map the features to a logit vector with one logit per subject\n",
    "x = Dense(num_subjects)(features)\n",
    "# use softmax activation to convert the logits to class probabilities for each subject\n",
    "predictions = Activation(\"softmax\")(x)\n",
    "\n",
    "# create the model using the layers we defined previously\n",
    "logistic_regression = Model(inputs=features, outputs=predictions)\n",
    "\n",
    "# compile the model so that it uses Adam for optimization during training with cross-entropy loss\n",
    "logistic_regression.compile(optimizer=Adam(), loss=\"sparse_categorical_crossentropy\", metrics=[\"acc\"])\n",
    "\n",
    "# print out a summary of the model achitecture\n",
    "print(logistic_regression.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since the subjects have different numbers of images, \n",
    "# we need to balance how much each subject contributes to the cross-entropy loss\n",
    "class_weights = compute_class_weight(\"balanced\", np.unique(train_y), train_y)\n",
    "\n",
    "# train model, verbose set to 0 to supress output, wait a moment for training to complete\n",
    "logistic_regression.fit(train_features_x, train_y, validation_data=(test_features_x, test_y), \n",
    "                        class_weight=class_weights, \n",
    "                        epochs=75, batch_size=128, verbose=0)\n",
    "\n",
    "# evaluate model, get train/test accuracy\n",
    "train_eig_pred = np.argmax(logistic_regression.predict(train_features_x), axis=1)\n",
    "test_eig_pred = np.argmax(logistic_regression.predict(test_features_x), axis=1)\n",
    "print(\"\\nTraining accuracy using Eigenfaces and logistic regression model: {}\".format(accuracy_score(train_y, train_eig_pred)))\n",
    "print(\"Testing accuracy using Eigenfaces and logistic regression model: {}\".format(accuracy_score(test_y, test_eig_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample CNN Model\n",
    "The Eigenfaces and logistic regression model doesn't perform that well on the unseen test set. Let's see how a simple CNN model compares.\n",
    "\n",
    "Rather than dealing with vectors, we will begin working with the grayscale images directly. \n",
    "\n",
    "Note: CNN learns convolution filters which extract the most useful features. Then, a small neural network at the end of the CNN architecture performs the multi-class classification. Therefore, the CNN will make things less complex for us as the CNN will learn to perform both feature extraction and classification! \n",
    "\n",
    "Let's get going!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specifying the input size of the images\n",
    "images = Input((train_x.shape[1], train_x.shape[2], 1,))\n",
    "# a convolution layer of 32 filters of size 9x9 to extract features (valid padding)\n",
    "x = Conv2D(32, padding=\"valid\", kernel_size=(9,9))(images)\n",
    "# a maxpooling layer to down-sample features with pool size (2, 2)\n",
    "x = MaxPool2D(pool_size=(2,2))(x)\n",
    "# another convolution layer of 64 filters of size 11x11 to extract features (valid padding)\n",
    "x = Conv2D(64, padding=\"valid\", kernel_size=(11,11))(x)\n",
    "# a maxpooling layer to down-sample features with pool size (2, 2)\n",
    "x = MaxPool2D(pool_size=(2,2))(x)\n",
    "# flatten extracted features to form feature vector\n",
    "x = Flatten()(x)\n",
    "# a drop out layer for regularization (25% probability)\n",
    "x = Dropout(0.25)(x)\n",
    "# first fully-connected layer to map the features to vectors of size 256\n",
    "x = Dense(256)(x)\n",
    "# anoter drop out layer for regularization (25% probability)\n",
    "x = Dropout(0.25)(x)\n",
    "# a second fully-connected layer to map the features to a logit vector with one logit per subject\n",
    "x = Dense(62)(x)\n",
    "# use softmax activation to convert the logits to class probabilities for each subject\n",
    "predictions = Activation(activation=\"softmax\")(x)\n",
    "\n",
    "# create the model using the layers we defined previously\n",
    "sample_cnn = Model(inputs=images, outputs=predictions)\n",
    "\n",
    "# compile the model so that it uses Adam for optimization during training with cross-entropy loss\n",
    "sample_cnn.compile(optimizer=Adam(), loss=\"sparse_categorical_crossentropy\", metrics=[\"acc\"])\n",
    "\n",
    "# print out a summary of the model achitecture\n",
    "print(sample_cnn.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since the subjects have different numbers of images, \n",
    "# we need to balance how much each subject contributes to the cross-entropy loss\n",
    "class_weights = compute_class_weight(\"balanced\", np.unique(train_y), train_y)\n",
    "\n",
    "# train model\n",
    "sample_cnn.fit(train_x, train_y, validation_data=(test_x, test_y), \n",
    "               class_weight=class_weights, \n",
    "               epochs=15, batch_size=64, verbose=1)\n",
    "\n",
    "# evaluate model, get train/test accuracy\n",
    "train_pred = np.argmax(sample_cnn.predict(train_x), axis=1)\n",
    "test_pred = np.argmax(sample_cnn.predict(test_x), axis=1)\n",
    "print(\"\\nTraining accuracy using sample CNN model: {}\".format(accuracy_score(train_y, train_pred)))\n",
    "print(\"Testing accuracy using sample CNN model: {}\\n\".format(accuracy_score(test_y, test_pred)))\n",
    "\n",
    "print(\"The sample CNN model beat the Eigenfaces and logistic regression model! :)\")\n",
    "print(\"Training accuracy using Eigenfaces and logistic regression model: {}\".format(accuracy_score(train_y, train_eig_pred)))\n",
    "print(\"Testing accuracy using Eigenfaces and logistic regression model: {}\".format(accuracy_score(test_y, test_eig_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More tasks\n",
    "\n",
    "2. Build three CNN models which surpass the traditional Eigenface method test accuracy. In each model use different architectures and optimizers. Points will be not be awarded if models architectures are not sufficiently different \n",
    "3. Build a fourth CNN model which achieves >70% test accuracy \n",
    "4. Display a correctly identified image and a training image corresponding to the correct training subject \n",
    "5. Display a incorrectly identified image and a training image corresponding to the correct training subject "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MODEL 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Whats new?\n",
    "# change padding to same\n",
    "# tanh as the activation for conv and dense layers.\n",
    "# Smaller kernel sizes and no dropout layer. lr = 0..001\n",
    "# Using average pool instead of maxpool\n",
    "\n",
    "images = Input((train_x.shape[1], train_x.shape[2], 1,))\n",
    "x = Conv2D(64, padding=\"same\", kernel_size=(5,5), activation=\"tanh\")(images)\n",
    "x = AveragePooling2D(pool_size=(2,2))(x)\n",
    "x = Conv2D(32, padding=\"same\", kernel_size=(5,5), activation=\"tanh\")(x)\n",
    "x = AveragePooling2D(pool_size=(2,2))(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(128, activation = \"tanh\")(x)\n",
    "x = Dense(128, activation = \"tanh\")(x)\n",
    "x = Dense(62)(x)\n",
    "predictions = Activation(activation=\"softmax\")(x)\n",
    "\n",
    "sample_cnn = Model(inputs=images, outputs=predictions)\n",
    "\n",
    "sample_cnn.compile(optimizer=Adam(learning_rate = 0.001), loss=\"sparse_categorical_crossentropy\", metrics=[\"acc\"])\n",
    "\n",
    "print(sample_cnn.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = compute_class_weight(\"balanced\", np.unique(train_y), train_y)\n",
    "\n",
    "# train model\n",
    "sample_cnn.fit(train_x, train_y, validation_data=(test_x, test_y), \n",
    "               class_weight=class_weights, \n",
    "               epochs=25, batch_size=64, verbose=1)\n",
    "\n",
    "# evaluate model, get train/test accuracy\n",
    "train_pred = np.argmax(sample_cnn.predict(train_x), axis=1)\n",
    "test_pred = np.argmax(sample_cnn.predict(test_x), axis=1)\n",
    "print(\"\\nTraining accuracy using sample CNN model: {}\".format(accuracy_score(train_y, train_pred)))\n",
    "print(\"Testing accuracy using sample CNN model: {}\\n\".format(accuracy_score(test_y, test_pred)))\n",
    "\n",
    "print(\"Training accuracy using Eigenfaces and logistic regression model: {}\".format(accuracy_score(train_y, train_eig_pred)))\n",
    "print(\"Testing accuracy using Eigenfaces and logistic regression model: {}\".format(accuracy_score(test_y, test_eig_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MODEL 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# whats new?\n",
    "# change padding to same\n",
    "# add relu activations\n",
    "# change in hyperparameters\n",
    "# 4 convolutions without dense layers\n",
    "\n",
    "images = Input((train_x.shape[1], train_x.shape[2], 1,))\n",
    "x = Conv2D(64, padding=\"same\", kernel_size=(10,10), activation=\"relu\")(images)\n",
    "x = MaxPool2D(pool_size=(4,4))(x)\n",
    "x = Conv2D(32, padding=\"same\", kernel_size=(10,10), activation=\"relu\")(x)\n",
    "x = MaxPool2D(pool_size=(2,2))(x)\n",
    "x = Conv2D(32, padding=\"same\", kernel_size=(5,5), activation=\"relu\")(x)\n",
    "x = MaxPool2D(pool_size=(2,2))(x)\n",
    "x = Conv2D(32, padding=\"same\", kernel_size=(5,5), activation=\"relu\")(x)\n",
    "x = MaxPool2D(pool_size=(2,2))(x)\n",
    "x = Flatten()(x)\n",
    "x = Dropout(0.25)(x)\n",
    "x = Dense(62)(x)\n",
    "predictions = Activation(activation=\"softmax\")(x)\n",
    "\n",
    "sample_cnn = Model(inputs=images, outputs=predictions)\n",
    "\n",
    "sample_cnn.compile(optimizer=RMSprop(), loss=\"sparse_categorical_crossentropy\", metrics=[\"acc\"])\n",
    "\n",
    "print(sample_cnn.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = compute_class_weight(\"balanced\", np.unique(train_y), train_y)\n",
    "\n",
    "# train model\n",
    "sample_cnn.fit(train_x, train_y, validation_data=(test_x, test_y), \n",
    "               class_weight=class_weights, \n",
    "               epochs=45, batch_size=64, verbose=1)\n",
    "\n",
    "# evaluate model, get train/test accuracy\n",
    "train_pred = np.argmax(sample_cnn.predict(train_x), axis=1)\n",
    "test_pred = np.argmax(sample_cnn.predict(test_x), axis=1)\n",
    "print(\"\\nTraining accuracy using sample CNN model: {}\".format(accuracy_score(train_y, train_pred)))\n",
    "print(\"Testing accuracy using sample CNN model: {}\\n\".format(accuracy_score(test_y, test_pred)))\n",
    "\n",
    "print(\"Training accuracy using Eigenfaces and logistic regression model: {}\".format(accuracy_score(train_y, train_eig_pred)))\n",
    "print(\"Testing accuracy using Eigenfaces and logistic regression model: {}\".format(accuracy_score(test_y, test_eig_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MODEL3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# whats new?\n",
    "# Adding dense layer before convolution\n",
    "# change padding to same\n",
    "# add relu activations\n",
    "# change in hyperparameters\n",
    "\n",
    "num_filters = 50\n",
    "filter_sizes = [(5,5),(7,7),(10, 10)]\n",
    "\n",
    "images = Input((train_x.shape[1], train_x.shape[2], 1,))\n",
    "pooled_outputs = []\n",
    "for i in range(len(filter_sizes)):\n",
    "    conv = Conv2D(num_filters, kernel_size=filter_sizes[i], padding='same')(images)\n",
    "    conv = MaxPool2D(pool_size=(2,2))(conv)\n",
    "    pooled_outputs.append(conv)\n",
    "x = concatenate(pooled_outputs)\n",
    "x = Flatten()(x)\n",
    "x = Dense(100, activation=\"relu\")(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(50, activation=\"relu\")(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(62)(x)\n",
    "predictions = Activation(activation=\"softmax\")(x)\n",
    "\n",
    "sample_cnn = Model(inputs=images, outputs=predictions)\n",
    "\n",
    "sample_cnn.compile(optimizer=Adagrad(learning_rate = 0.01), loss=\"sparse_categorical_crossentropy\", metrics=[\"acc\"])\n",
    "\n",
    "print(sample_cnn.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class_weights = compute_class_weight(\"balanced\", np.unique(train_y), train_y)\n",
    "\n",
    "sample_cnn.fit(train_x, train_y, validation_data=(test_x, test_y), \n",
    "               class_weight=class_weights, \n",
    "               epochs=50, batch_size=64, verbose=1)\n",
    "\n",
    "train_pred = np.argmax(sample_cnn.predict(train_x), axis=1)\n",
    "test_pred = np.argmax(sample_cnn.predict(test_x), axis=1)\n",
    "print(\"\\nTraining accuracy using sample CNN model: {}\".format(accuracy_score(train_y, train_pred)))\n",
    "print(\"Testing accuracy using sample CNN model: {}\\n\".format(accuracy_score(test_y, test_pred)))\n",
    "\n",
    "print(\"Training accuracy using Eigenfaces and logistic regression model: {}\".format(accuracy_score(train_y, train_eig_pred)))\n",
    "print(\"Testing accuracy using Eigenfaces and logistic regression model: {}\".format(accuracy_score(test_y, test_eig_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MODEL 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "images = Input((train_x.shape[1], train_x.shape[2], 1,))\n",
    "x = Conv2D(32, padding=\"same\", kernel_size=(10,10))(images)\n",
    "x = MaxPool2D(pool_size=(4,4))(x)\n",
    "x = Conv2D(64, padding=\"same\", kernel_size=(5,5))(x)\n",
    "x = MaxPool2D(pool_size=(2,2))(x)\n",
    "x = Flatten()(x)\n",
    "x = Dropout(0.25)(x)\n",
    "x = Dense(128, activation=\"relu\")(x)\n",
    "x = Dropout(0.25)(x)\n",
    "x = Dense(128, activation=\"relu\")(x)\n",
    "x = Dropout(0.25)(x)\n",
    "x = Dense(62)(x)\n",
    "predictions = Activation(activation=\"softmax\")(x)\n",
    "\n",
    "# create the model using the layers we defined previously\n",
    "sample_cnn = Model(inputs=images, outputs=predictions)\n",
    "\n",
    "# compile the model so that it uses Adam for optimization during training with cross-entropy loss\n",
    "sample_cnn.compile(optimizer=Adam(), loss=\"sparse_categorical_crossentropy\", metrics=[\"acc\"])\n",
    "\n",
    "# print out a summary of the model achitecture\n",
    "print(sample_cnn.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class_weights = compute_class_weight(\"balanced\", np.unique(train_y), train_y)\n",
    "\n",
    "# train model\n",
    "sample_cnn.fit(train_x, train_y, validation_data=(test_x, test_y), \n",
    "               class_weight=class_weights, \n",
    "               epochs=25, batch_size=64, verbose=1)\n",
    "\n",
    "# evaluate model, get train/test accuracy\n",
    "train_pred = np.argmax(sample_cnn.predict(train_x), axis=1)\n",
    "test_pred = np.argmax(sample_cnn.predict(test_x), axis=1)\n",
    "print(\"\\nTraining accuracy using sample CNN model: {}\".format(accuracy_score(train_y, train_pred)))\n",
    "print(\"Testing accuracy using sample CNN model: {}\\n\".format(accuracy_score(test_y, test_pred)))\n",
    "\n",
    "print(\"Training accuracy using Eigenfaces and logistic regression model: {}\".format(accuracy_score(train_y, train_eig_pred)))\n",
    "print(\"Testing accuracy using Eigenfaces and logistic regression model: {}\".format(accuracy_score(test_y, test_eig_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Display a correctly identified image and a training image corresponding to the correct training subject (1 pts.)\n",
    "Display a incorrectly identified image and a training image corresponding to the correct training subject (1 pts.)\n",
    "\n",
    "rnd_img = data_x[rnd_idx]\n",
    "plt.figure()\n",
    "plt.imshow(rnd_img[:, :, 0], cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correct prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = np.argmax(sample_cnn.predict(test_x), axis=1)\n",
    "print(\"Is prediction for 1st image same as its label? \",test_pred[0] == test_y[0])\n",
    "print(\"Class of image is\", test_y[0])\n",
    "print(\"Correctly tagged image - \")\n",
    "rnd_img = test_x[0]\n",
    "plt.figure()\n",
    "plt.imshow(rnd_img[:, :, 0], cmap=\"gray\")\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\\nImage of same class from train set\")\n",
    "train_img = train_x[np.where(train_y==test_y[0])[0][0]]\n",
    "plt.figure()\n",
    "plt.imshow(train_img[:, :, 0], cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Incorrect prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we see the 2nd test image is correctly predicted\n",
    "test_pred = np.argmax(sample_cnn.predict(test_x), axis=1)\n",
    "print(\"Is prediction for 1st image same as its label? \",test_pred[1] == test_y[1])\n",
    "print(\"Class of image is\", test_y[1], \"  but predicted class is \", test_pred[1])\n",
    "print(\"Incorrectly tagged image - \")\n",
    "rnd_img = test_x[1]\n",
    "plt.figure()\n",
    "plt.imshow(rnd_img[:, :, 0], cmap=\"gray\")\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\\nImage of same class from train set\")\n",
    "train_img = train_x[np.where(train_y==test_y[1])[0][0]]\n",
    "plt.figure()\n",
    "plt.imshow(train_img[:, :, 0], cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Complete the sample CNN as specified by the comments (2 pts.)....Done\n",
    "#Build three CNN models which surpass the traditional Eigenface method test accuracy. In each model use different architectures and optimizers. Points will be not be awarded if models architectures are not sufficiently different (3 pts.)\n",
    "#model-1: Done\n",
    "#model-2: Done\n",
    "#model-3: Done\n",
    "#Build a fourth CNN model which achieves >70% test accuracy (3 pts.): i got 72% test accuracy\n",
    "#Display a correctly identified image and a training image corresponding to the correct training subject (1 pts.): Done\n",
    "#Display a incorrectly identified image and a training image corresponding to the correct training subject (1 pts.): Done\n",
    "\n",
    "#..1,2,3 are the models and all have accuracy > 60\n",
    "# 4th model the testing accuracy is more than 70%"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
