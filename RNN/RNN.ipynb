{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import SimpleRNN, LSTM, GRU, Dense, Dropout, Input\n",
    "from keras.models import Model\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.preprocessing.text import Tokenizer, one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>gender</th>\n",
       "      <th>probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Judythe</td>\n",
       "      <td>F</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Nitesh</td>\n",
       "      <td>M</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Lan</td>\n",
       "      <td>F</td>\n",
       "      <td>0.73896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Latish</td>\n",
       "      <td>F</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Neana</td>\n",
       "      <td>F</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      name gender  probability\n",
       "0  Judythe      F      1.00000\n",
       "1   Nitesh      M      1.00000\n",
       "2      Lan      F      0.73896\n",
       "3   Latish      F      1.00000\n",
       "4    Neana      F      1.00000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"name_gender.csv\")\n",
    "df = df.sample(frac=1).reset_index(drop=True)  ### Shuffling here so we can select random data just by array slicing\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = list(df[\"name\"])\n",
    "for i in range(len(names)):\n",
    "    names[i] = names[i].lower()\n",
    "    names[i] = ([ord(c) - ord('a') + 1 for c in names[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len = max([len(i) for i in names])\n",
    "max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = pad_sequences(names, padding=\"pre\", maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.000000    84664\n",
       "0.500000      118\n",
       "0.666667       65\n",
       "0.545455       54\n",
       "0.750000       35\n",
       "            ...  \n",
       "0.912764        1\n",
       "0.988346        1\n",
       "0.643312        1\n",
       "0.722359        1\n",
       "0.877899        1\n",
       "Name: probability, Length: 8306, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"probability\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "genders = df[\"gender\"].replace(\"M\", 1).replace(\"F\", 0).to_list()\n",
    "labels = to_categorical(genders, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = to_categorical(names, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "MAX_LEN = max_len\n",
    "NUM_CLASSES = 2\n",
    "NUM_INPUT_CLASSES = 27"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN cells - Simple RNN, LSTM and GRU\n",
    "def get_lstm():\n",
    "    inp = Input(shape=(MAX_LEN, NUM_INPUT_CLASSES))\n",
    "    x = LSTM(64, return_sequences=True, activation=\"relu\")(inp)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = LSTM(64, activation=\"relu\")(x)\n",
    "    x = Dense(50, activation=\"relu\")(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    out = Dense(2, activation=\"softmax\")(x)\n",
    "    model = Model(inp, out)\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "#     print(model.summary())\n",
    "    return model\n",
    "\n",
    "def get_rnn():\n",
    "    inp = Input(shape=(MAX_LEN, NUM_INPUT_CLASSES))\n",
    "    x = SimpleRNN(64, return_sequences=True, activation=\"relu\")(inp)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = SimpleRNN(64, activation=\"relu\")(x)\n",
    "    x = Dense(50, activation=\"relu\")(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    out = Dense(2, activation=\"softmax\")(x)\n",
    "    model = Model(inp, out)\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "#     print(model.summary())\n",
    "    return model\n",
    "\n",
    "def get_gru():\n",
    "    inp = Input(shape=(MAX_LEN, NUM_INPUT_CLASSES))\n",
    "    x = GRU(64, return_sequences=True, activation=\"relu\")(inp)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = GRU(64, activation=\"relu\")(x)\n",
    "    x = Dense(50, activation=\"relu\")(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    out = Dense(2, activation=\"softmax\")(x)\n",
    "    model = Model(inp, out)\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "#     print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model_type, data_frac):\n",
    "    total = inputs.shape[0]\n",
    "    X = inputs[:int(total*data_frac)]\n",
    "    Y = labels[:int(total*data_frac)]\n",
    "    trainX, testX, trainY, testY = train_test_split(X, Y, test_size = 0.2)\n",
    "    if model_type == \"lstm\":\n",
    "        model = get_lstm()\n",
    "    elif model_type == \"rnn\":\n",
    "        model = get_rnn()\n",
    "    else:\n",
    "        model = get_gru()\n",
    "    print(\"MODEL TYPE:\", model_type,\"  Data :\", data_frac*100, \"%\")\n",
    "    model.fit(trainX, trainY,epochs = 1, batch_size=BATCH_SIZE, verbose = 0)\n",
    "    y_pred = model.predict(testX).argmax(axis = 1)\n",
    "    acc = accuracy_score(testY.argmax(axis = 1), y_pred)\n",
    "    print(\"Accuracy: \", acc)\n",
    "    cm = confusion_matrix(testY.argmax(axis = 1), y_pred)\n",
    "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    print(\"Class-wise accuracy:\",cm.diagonal())\n",
    "    print(\"\\n---------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset size (Randomly select 25%, 50%, 75% and 100% of the data) . For each partial dataset use 80% as training data.\n",
    "types = [\"lstm\", \"gru\", \"rnn\"]\n",
    "fracs = [0.25, 0.5, 0.75, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL TYPE: lstm   Data : 25.0 %\n",
      "Accuracy:  0.696969696969697\n",
      "Class-wise accuracy: [0.87138584 0.39586919]\n",
      "\n",
      "---------------------------\n",
      "\n",
      "MODEL TYPE: lstm   Data : 50.0 %\n",
      "Accuracy:  0.8045880248342628\n",
      "Class-wise accuracy: [0.89267405 0.65046296]\n",
      "\n",
      "---------------------------\n",
      "\n",
      "MODEL TYPE: lstm   Data : 75.0 %\n",
      "Accuracy:  0.8269257752209906\n",
      "Class-wise accuracy: [0.86574947 0.76016027]\n",
      "\n",
      "---------------------------\n",
      "\n",
      "MODEL TYPE: lstm   Data : 100 %\n",
      "Accuracy:  0.8297905924444912\n",
      "Class-wise accuracy: [0.84808861 0.79839977]\n",
      "\n",
      "---------------------------\n",
      "\n",
      "MODEL TYPE: gru   Data : 25.0 %\n",
      "Accuracy:  0.797979797979798\n",
      "Class-wise accuracy: [0.92379993 0.58657642]\n",
      "\n",
      "---------------------------\n",
      "\n",
      "MODEL TYPE: gru   Data : 50.0 %\n",
      "Accuracy:  0.8233189519099232\n",
      "Class-wise accuracy: [0.87778147 0.72910083]\n",
      "\n",
      "---------------------------\n",
      "\n",
      "MODEL TYPE: gru   Data : 75.0 %\n",
      "Accuracy:  0.8335204153220148\n",
      "Class-wise accuracy: [0.85866548 0.79035639]\n",
      "\n",
      "---------------------------\n",
      "\n",
      "MODEL TYPE: gru   Data : 100 %\n",
      "Accuracy:  0.8315268862464484\n",
      "Class-wise accuracy: [0.81810617 0.8546079 ]\n",
      "\n",
      "---------------------------\n",
      "\n",
      "MODEL TYPE: rnn   Data : 25.0 %\n",
      "Accuracy:  0.8120791245791246\n",
      "Class-wise accuracy: [0.89847716 0.67000556]\n",
      "\n",
      "---------------------------\n",
      "\n",
      "MODEL TYPE: rnn   Data : 50.0 %\n",
      "Accuracy:  0.8306850468273177\n",
      "Class-wise accuracy: [0.82833743 0.83490288]\n",
      "\n",
      "---------------------------\n",
      "\n",
      "MODEL TYPE: rnn   Data : 75.0 %\n",
      "Accuracy:  0.8462186053037744\n",
      "Class-wise accuracy: [0.86158475 0.82010983]\n",
      "\n",
      "---------------------------\n",
      "\n",
      "MODEL TYPE: rnn   Data : 100 %\n",
      "Accuracy:  0.8548879301273282\n",
      "Class-wise accuracy: [0.8865254  0.79787705]\n",
      "\n",
      "---------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for t in types:\n",
    "    for f in fracs:\n",
    "        train_model(t, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = list(df[\"name\"])\n",
    "for i in range(len(names)):\n",
    "    names[i] = names[i].lower()\n",
    "    names[i] = ([ord(c) - ord('a') + 1 for c in names[i]])\n",
    "genders = df[\"gender\"].replace(\"M\", 1).replace(\"F\", 0).to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    inp = Input(shape=(MAX_LEN-1, NUM_INPUT_CLASSES))\n",
    "    x = LSTM(64, return_sequences=True)(inp)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = LSTM(64)(x)\n",
    "    x = Dense(50, activation=\"relu\")(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    out = Dense(NUM_INPUT_CLASSES, activation=\"softmax\")(x)\n",
    "    model = Model(inp, out)\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((95026, 14, 27), (95026, 27))"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = inputs[:, :-1, :]\n",
    "Y = inputs[:, -1, :]\n",
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((34722, 15, 27), (60304, 15, 27))"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_m = []\n",
    "X_f = []\n",
    "for i in range(len(genders)):\n",
    "    if genders[i] == 1:\n",
    "        X_m.append(names[i])\n",
    "    else:\n",
    "        X_f.append(names[i])\n",
    "X_m = pad_sequences(X_m, padding=\"pre\", maxlen=max_len)\n",
    "X_m = to_categorical(X_m)\n",
    "X_f = pad_sequences(X_f, padding=\"pre\", maxlen=max_len)\n",
    "X_f = to_categorical(X_f)\n",
    "X_m.shape, X_f.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "34722/34722 [==============================] - 36s 1ms/step - loss: 2.7173 - acc: 0.2652\n",
      "Epoch 2/25\n",
      "34722/34722 [==============================] - 19s 552us/step - loss: 2.4650 - acc: 0.3046\n",
      "Epoch 3/25\n",
      "34722/34722 [==============================] - 20s 563us/step - loss: 2.2156 - acc: 0.3661\n",
      "Epoch 4/25\n",
      "34722/34722 [==============================] - 20s 575us/step - loss: 2.1049 - acc: 0.3936\n",
      "Epoch 5/25\n",
      "34722/34722 [==============================] - 19s 538us/step - loss: 2.0219 - acc: 0.4105\n",
      "Epoch 6/25\n",
      "34722/34722 [==============================] - 20s 562us/step - loss: 1.9624 - acc: 0.4229\n",
      "Epoch 7/25\n",
      "34722/34722 [==============================] - 19s 540us/step - loss: 1.9178 - acc: 0.4369\n",
      "Epoch 8/25\n",
      "34722/34722 [==============================] - 20s 568us/step - loss: 1.8807 - acc: 0.4460\n",
      "Epoch 9/25\n",
      "34722/34722 [==============================] - 20s 567us/step - loss: 1.8452 - acc: 0.4552\n",
      "Epoch 10/25\n",
      "34722/34722 [==============================] - 19s 540us/step - loss: 1.8236 - acc: 0.4619\n",
      "Epoch 11/25\n",
      "34722/34722 [==============================] - 20s 563us/step - loss: 1.7917 - acc: 0.4706\n",
      "Epoch 12/25\n",
      "34722/34722 [==============================] - 19s 560us/step - loss: 1.7667 - acc: 0.4731\n",
      "Epoch 13/25\n",
      "34722/34722 [==============================] - 19s 537us/step - loss: 1.7419 - acc: 0.4845\n",
      "Epoch 14/25\n",
      "34722/34722 [==============================] - 20s 580us/step - loss: 1.7181 - acc: 0.4906\n",
      "Epoch 15/25\n",
      "34722/34722 [==============================] - 19s 561us/step - loss: 1.6982 - acc: 0.4949\n",
      "Epoch 16/25\n",
      "34722/34722 [==============================] - 19s 534us/step - loss: 1.6798 - acc: 0.5005\n",
      "Epoch 17/25\n",
      "34722/34722 [==============================] - 20s 568us/step - loss: 1.6588 - acc: 0.5063\n",
      "Epoch 18/25\n",
      "34722/34722 [==============================] - 19s 558us/step - loss: 1.6412 - acc: 0.5104\n",
      "Epoch 19/25\n",
      "34722/34722 [==============================] - 18s 532us/step - loss: 1.6238 - acc: 0.5149\n",
      "Epoch 20/25\n",
      "34722/34722 [==============================] - 21s 602us/step - loss: 1.6060 - acc: 0.5216\n",
      "Epoch 21/25\n",
      "34722/34722 [==============================] - 21s 596us/step - loss: 1.5923 - acc: 0.5231\n",
      "Epoch 22/25\n",
      "34722/34722 [==============================] - 19s 545us/step - loss: 1.5754 - acc: 0.5272\n",
      "Epoch 23/25\n",
      "34722/34722 [==============================] - 20s 567us/step - loss: 1.5666 - acc: 0.5278\n",
      "Epoch 24/25\n",
      "34722/34722 [==============================] - 19s 540us/step - loss: 1.5505 - acc: 0.5327\n",
      "Epoch 25/25\n",
      "34722/34722 [==============================] - 20s 569us/step - loss: 1.5423 - acc: 0.5370\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1db588a7a88>"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "male_model = get_model()\n",
    "male_model.fit(X_m[:, :-1,:], X_m[:, -1, :], epochs=25, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60304/60304 [==============================] - 64s 1ms/step - loss: 1.9239 - acc: 0.4368\n",
      "Epoch 2/10\n",
      "60304/60304 [==============================] - 44s 727us/step - loss: 1.5656 - acc: 0.5150\n",
      "Epoch 3/10\n",
      "60304/60304 [==============================] - 44s 724us/step - loss: 1.4303 - acc: 0.5475\n",
      "Epoch 4/10\n",
      "60304/60304 [==============================] - 44s 732us/step - loss: 1.3530 - acc: 0.5644\n",
      "Epoch 5/10\n",
      "60304/60304 [==============================] - 56s 923us/step - loss: 1.3029 - acc: 0.5760\n",
      "Epoch 6/10\n",
      "60304/60304 [==============================] - 59s 974us/step - loss: 1.2687 - acc: 0.5825\n",
      "Epoch 7/10\n",
      "60304/60304 [==============================] - 56s 923us/step - loss: 1.2416 - acc: 0.5896\n",
      "Epoch 8/10\n",
      "60304/60304 [==============================] - 63s 1ms/step - loss: 1.2201 - acc: 0.5967\n",
      "Epoch 9/10\n",
      "60304/60304 [==============================] - 53s 881us/step - loss: 1.1993 - acc: 0.6003\n",
      "Epoch 10/10\n",
      "60304/60304 [==============================] - 53s 881us/step - loss: 1.1807 - acc: 0.6070\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1db468c4048>"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "female_model = get_model()\n",
    "female_model.fit(X_f[:, :-1,:], X_f[:, -1, :], epochs=10, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_text(inp):\n",
    "    s = \"\"\n",
    "    for i in inp:\n",
    "        if i==0:\n",
    "            continue\n",
    "        s+= chr(i+ord('a') -1)\n",
    "    return s\n",
    "def generate_names(model, l):\n",
    "    name = [[np.random.randint(low = 1, high = 27)]]\n",
    "    for i in range(l-1):\n",
    "        X_in = pad_sequences(name, maxlen=max_len-1, padding=\"pre\")\n",
    "        X_in = to_categorical(X_in, num_classes=27)\n",
    "        next_letter = model.predict(X_in).argmax(axis = 1)[0]\n",
    "        name = [np.append(name, [next_letter])]\n",
    "    name = to_text(name[0])\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MALE NAMES\n",
      "noyel\n",
      "wynerton\n",
      "jinondonyoses\n",
      "cellendone\n",
      "alondonyoneshi\n",
      "edynell\n",
      "edynelles\n",
      "cellen\n",
      "wynertonesh\n",
      "jinondonyos\n",
      "tonellond\n",
      "tonellondo\n",
      "edynelles\n",
      "sonellon\n",
      "onell\n",
      "hinondo\n",
      "kilondonesh\n",
      "fyellynertone\n",
      "sonell\n",
      "alondonyoneshi\n",
      "\n",
      "\n",
      " FEMALE NAMES\n",
      "farahaha\n",
      "xanahahaha\n",
      "uanahaha\n",
      "naiahaha\n",
      "daela\n",
      "naiahahah\n",
      "yahanahahaha\n",
      "naiahahahahah\n",
      "barahah\n",
      "yahanahahahaha\n",
      "yahanahahahaha\n",
      "jahanaha\n",
      "iahanahahahaha\n",
      "uanahahah\n",
      "eahahahaha\n",
      "naiaha\n",
      "daelaha\n",
      "anahahahaha\n",
      "ganahahahahah\n",
      "anahahah\n"
     ]
    }
   ],
   "source": [
    "# Generate 20 male names and 20 female names\n",
    "print(\"MALE NAMES\")\n",
    "for i in range(20):\n",
    "    name_len = np.random.randint(low = 5, high = 15)\n",
    "    print(generate_names(male_model, name_len))\n",
    "\n",
    "print(\"\\n\\n FEMALE NAMES\")\n",
    "for i in range(20):\n",
    "    name_len = np.random.randint(low = 5, high = 15)\n",
    "    print(generate_names(female_model, name_len))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19080, 15, 27)"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = []\n",
    "for i in range(len(inputs)):\n",
    "    if names[i][0] in set({1, 13, 26}):\n",
    "        X.append(names[i])\n",
    "X = pad_sequences(X, padding=\"pre\", maxlen=max_len)\n",
    "X = to_categorical(X)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((19080, 14, 27), (19080, 27))"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX = X[:, :-1, :]\n",
    "trainY = X[:, -1, :]\n",
    "trainX.shape, trainY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "19080/19080 [==============================] - 41s 2ms/step - loss: 2.5748 - acc: 0.2932\n",
      "Epoch 2/25\n",
      "19080/19080 [==============================] - 18s 933us/step - loss: 2.3508 - acc: 0.3081\n",
      "Epoch 3/25\n",
      "19080/19080 [==============================] - 18s 931us/step - loss: 2.2933 - acc: 0.3103\n",
      "Epoch 4/25\n",
      "19080/19080 [==============================] - 21s 1ms/step - loss: 2.2256 - acc: 0.3218\n",
      "Epoch 5/25\n",
      "19080/19080 [==============================] - 20s 1ms/step - loss: 2.1099 - acc: 0.3862\n",
      "Epoch 6/25\n",
      "19080/19080 [==============================] - 19s 1ms/step - loss: 1.9898 - acc: 0.4193\n",
      "Epoch 7/25\n",
      "19080/19080 [==============================] - 19s 1ms/step - loss: 1.9291 - acc: 0.4323\n",
      "Epoch 8/25\n",
      "19080/19080 [==============================] - 22s 1ms/step - loss: 1.8751 - acc: 0.4384\n",
      "Epoch 9/25\n",
      "19080/19080 [==============================] - 21s 1ms/step - loss: 1.8443 - acc: 0.4400\n",
      "Epoch 10/25\n",
      "19080/19080 [==============================] - 19s 983us/step - loss: 1.8107 - acc: 0.4505\n",
      "Epoch 11/25\n",
      "19080/19080 [==============================] - 19s 1ms/step - loss: 1.7820 - acc: 0.4568\n",
      "Epoch 12/25\n",
      "19080/19080 [==============================] - 19s 980us/step - loss: 1.7557 - acc: 0.4591\n",
      "Epoch 13/25\n",
      "19080/19080 [==============================] - 19s 1ms/step - loss: 1.7333 - acc: 0.4682\n",
      "Epoch 14/25\n",
      "19080/19080 [==============================] - 20s 1ms/step - loss: 1.7131 - acc: 0.4708\n",
      "Epoch 15/25\n",
      "19080/19080 [==============================] - 19s 971us/step - loss: 1.6916 - acc: 0.4761\n",
      "Epoch 16/25\n",
      "19080/19080 [==============================] - 19s 1ms/step - loss: 1.6699 - acc: 0.4831\n",
      "Epoch 17/25\n",
      "19080/19080 [==============================] - 19s 1ms/step - loss: 1.6561 - acc: 0.4864\n",
      "Epoch 18/25\n",
      "19080/19080 [==============================] - 19s 984us/step - loss: 1.6336 - acc: 0.4950\n",
      "Epoch 19/25\n",
      "19080/19080 [==============================] - 20s 1ms/step - loss: 1.6301 - acc: 0.4922\n",
      "Epoch 20/25\n",
      "19080/19080 [==============================] - 19s 1ms/step - loss: 1.6123 - acc: 0.4972\n",
      "Epoch 21/25\n",
      "19080/19080 [==============================] - 19s 997us/step - loss: 1.6068 - acc: 0.5005\n",
      "Epoch 22/25\n",
      "19080/19080 [==============================] - 19s 1ms/step - loss: 1.5892 - acc: 0.5020\n",
      "Epoch 23/25\n",
      "19080/19080 [==============================] - 19s 982us/step - loss: 1.5785 - acc: 0.5068\n",
      "Epoch 24/25\n",
      "19080/19080 [==============================] - 19s 995us/step - loss: 1.5688 - acc: 0.5075\n",
      "Epoch 25/25\n",
      "19080/19080 [==============================] - 19s 1ms/step - loss: 1.5605 - acc: 0.5088\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1da16328dc8>"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amz_model = get_model()\n",
    "amz_model.fit(trainX, trainY, epochs = 25, batch_size = BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_amz_names(model, l):\n",
    "    name = [[np.random.choice([1, 13, 26])]]\n",
    "    for i in range(l-1):\n",
    "        X_in = pad_sequences(name, maxlen=max_len-1, padding=\"pre\")\n",
    "        X_in = to_categorical(X_in, num_classes=27)\n",
    "        next_letter = model.predict(X_in).argmax(axis = 1)[0]\n",
    "        name = [np.append(name, [next_letter])]\n",
    "    name = to_text(name[0])\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Names starting with A, M or Z\n",
      "\n",
      "ziahanahahah\n",
      "ziahanahahahan\n",
      "ziahanaha\n",
      "mirahanahah\n",
      "adanahi\n",
      "mirahanah\n",
      "mirahana\n",
      "mirahan\n",
      "ziahanahahahan\n",
      "ziahanah\n",
      "ziahanaha\n",
      "adanahirahahan\n",
      "ziahanaha\n",
      "mirahana\n",
      "ziahanahahah\n",
      "ziahanahahaha\n",
      "ziahan\n",
      "adanahirahah\n",
      "miraha\n",
      "adanahirahah\n",
      "ziahan\n",
      "mirahanahaha\n",
      "ziaha\n",
      "mirah\n",
      "adana\n",
      "adanahiraha\n",
      "ziahanahahah\n",
      "adanahirahahan\n",
      "miraha\n",
      "adanahirahahan\n",
      "adanahirahaha\n",
      "adanahir\n",
      "ziahanahahah\n",
      "ziahanaha\n",
      "mirahan\n",
      "adanah\n",
      "ziaha\n",
      "mirah\n",
      "adanahiraha\n",
      "adanahirah\n",
      "ziaha\n",
      "ziahanah\n",
      "ziahanah\n",
      "mirahanah\n",
      "mirahanah\n",
      "adanahi\n",
      "ziahanaha\n",
      "miraha\n",
      "ziaha\n",
      "adanahira\n"
     ]
    }
   ],
   "source": [
    "# Train a language model using names starting with A, M, and Z.\n",
    "print(\"Names starting with A, M or Z\\n\")\n",
    "for i in range(50):\n",
    "    name_len = np.random.randint(low = 5, high = 15)\n",
    "    print(generate_amz_names(amz_model, name_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ... RNN Classifier: Three different versions (Simple, LSTM, GRU) of the classifier --> done!\n",
    "## ... This criterion is linked to a Learning OutcomePerformance of the classifiers --> done!\n",
    "## ... This criterion is linked to a Learning OutcomeGender specific language model for generating names --> done!\n",
    "## ... Language model to generate names starting with A, M, Z --> done!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ... to write the code, I reffered various links and wrote my own code.\n",
    "## ... references: \n",
    "## ... https://machinelearningmastery.com/how-to-develop-a-word-level-neural-language-model-in-keras/\n",
    "## ... https://machinelearningmastery.com/sequence-classification-lstm-recurrent-neural-networks-python-keras/\n",
    "## ... https://maelfabien.github.io/machinelearning/NLP_7/#data-pre-processing\n",
    "## ... https://adventuresinmachinelearning.com/recurrent-neural-networks-lstm-tutorial-tensorflow/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
